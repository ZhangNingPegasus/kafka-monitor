zookeeper:
  connect: ${zk.connect:192.168.6.166:2181,192.168.6.167:2181,192.168.0.197:2181}
database:
  needInitial: true
  name: ${db.name:kafka_monitor_test}
  host: ${db.host:192.168.6.167}
  port: ${db.port:3306}
  username: ${db.username:root}
  password: ${db.password:zhangningpegasus}
  retention:
    days: ${db.retention.days:3}
topic:
  blacklist: ${topic.blacklist:}

nacos:
  config:
  nacosLocalSnapshotPath: /wyyt/etc/acm/kafka-monitor
  nacosLogPath:  /wyyt/logs/kafka-monitor
  acmConfigPath: acmConfig.properties

server:
  port: 9999
  tomcat:
    uri-encoding: UTF-8
  compression:
    enabled: true
    mime-types: text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json,application/xml
  servlet:
    session:
      timeout: 180m
spring:
  application:
    name: kafka-monitor
  http:
    encoding:
      charset: UTF-8
      enabled: true
      force: true
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB
      max-request-size: 10MB
  aop:
    proxy-target-class: true
  jmx:
    default-domain: ${spring.application.name}
  freemarker:
    allow-session-override: true
    check-template-location: true
    suffix: .ftl
    content-type: text/html
    enabled: true
    cache: false
    template-loader-path: classpath:/templates/
    charset: UTF-8
    expose-request-attributes: true
    expose-session-attributes: true
    expose-spring-macro-helpers: true
    request-context-attribute: request
    settings:
      auto_import: common/spring.ftl as spring
      number_format: '0.##'
    #  datasource:
    #    platform: mysql
    #    type: com.alibaba.druid.pool.DruidDataSource
    #    driver-class-name: com.mysql.cj.jdbc.Driver
    #    url: jdbc:mysql://${database.host}:${database.port}/${database.name}?allowPublicKeyRetrieval=true&serverTimezone=CST&characterEncoding=utf8&useUnicode=true&autoReconnect=true&allowMultiQueries=true&useSSL=false&zeroDateTimeBehavior=CONVERT_TO_NULL
    #    username: ${database.username}
    #    password: ${database.password}
    #    druid:
    #      # 配置初始化大小
    #      initialSize: 10
    #      # 配置连接池中最小可用连接的个数
    #      minIdle: 100
    #      # 配置连接池中最大可用连接的个数
    #      maxActive: 500
    #      # 配置获取连接等待超时的时间, 单位是毫秒
    #      maxWait: 60000
    #      # 配置间隔多久才进行一次检测, 检测需要关闭的空闲连接, 单位是毫秒
    #      timeBetweenEvictionRunsMillis: 60000
    #      # 配置一个连接在池中最小生存的时间, 单位是毫秒
    #      minEvictableIdleTimeMillis: 300000
    #      validationQuery: SELECT 1
    #      validationQueryTimeout: 60000
    #      testWhileIdle: true
    #      testOnBorrow: false
    #      testOnReturn: false
    #      # 打开PSCache, 并且指定每个连接上PSCache的大小.分库分表较多的数据库，建议配置为false
    #      poolPreparedStatements: true
    #      maxPoolPreparedStatementPerConnectionSize: 20
    #      maxOpenPreparedStatements: 20
    #      connection-init-sqls: SET NAMES utf8mb4 COLLATE utf8mb4_unicode_ci

    #mybatis-plus:
    #  mapper-locations: classpath:com.pegasus.kafka.mapper/*Mapper.xml
    #  configuration:
    #    map-underscore-to-camel-case: true
    ## 这个配置会将执行的sql打印出来，在开发或测试的时候可以用
    #log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
